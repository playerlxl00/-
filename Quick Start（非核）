import numpy as np

# ==============================
# python实现代码原封不动
# ==============================
class LinearSVM:
    """
    普通线性 SVM（无核），使用次梯度下降优化 hinge loss
    """
    def __init__(self, lr=1e-3, C=1.0, epochs=1000):
        self.lr = lr
        self.C = C
        self.epochs = epochs
        self.w = None
        self.b = 0.0

    def fit(self, X, y):
        n_samples, n_features = X.shape
        self.w = np.zeros(n_features)
        self.b = 0.0

        for _ in range(self.epochs):
            for i in range(n_samples):
                condition = y[i] * (np.dot(self.w, X[i]) + self.b) >= 1
                if condition:
                    self.w -= self.lr * self.w
                else:
                    self.w -= self.lr * (self.w - self.C * y[i] * X[i])
                    self.b += self.lr * self.C * y[i]

    def predict(self, X):
        return np.sign(np.dot(X, self.w) + self.b)


# 模拟例子
# ==============================
# 1. 构造训练数据
# ==============================
X_train = np.array([
    [2, 3],
    [1, 1],
    [2, 0],
    [0, 1]
])

y_train = np.array([1, 1, -1, -1])


# ==============================
# 2. 初始化并训练 SVM
# ==============================
svm = LinearSVM(lr=1e-3, C=1.0, epochs=100)
svm.fit(X_train, y_train)

# 打印训练后的 w 和 b
print("训练后的 w:", svm.w)
print("训练后的 b:", svm.b)


# ==============================
# 3. 测试预测
# ==============================
X_test = np.array([
    [1, 2],  # 接近 +1 类
    [2, -1]  # 接近 -1 类
])

y_pred = svm.predict(X_test)
print("预测结果:", y_pred)
